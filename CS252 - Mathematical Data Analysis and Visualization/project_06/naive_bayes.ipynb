{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Samuel Munoz**\n",
    "\n",
    "Spring 2021\n",
    "\n",
    "CS 251: Data Analysis and Visualization\n",
    "\n",
    "Project 6: Supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "plt.style.use(['seaborn-colorblind', 'seaborn-darkgrid'])\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "np.set_printoptions(suppress=True, precision=5)\n",
    "\n",
    "# Automatically reload external modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Preprocess full spam email dataset \n",
    "\n",
    "Before you build a Naive Bayes spam email classifier, run the full spam email dataset through your preprocessing code.\n",
    "\n",
    "Download and extract the full **Enron** emails (*zip file should be ~29MB large*). You should see a base `enron` folder, with `spam` and `ham` subfolders when you extract the zip file (these are the 2 classes).\n",
    "\n",
    "Run the test code below to check everything over."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a) Preprocess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import email_preprocessor as epp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test `count_words` and `find_top_words`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq, num_emails = epp.count_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You found 32625 emails in the datset. You should have found 32625.\n"
     ]
    }
   ],
   "source": [
    "print(f'You found {num_emails} emails in the datset. You should have found 32625.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your top 5 words are\n",
      "['the', 'to', 'and', 'of', 'a']\n",
      "and they should be\n",
      "['the', 'to', 'and', 'of', 'a']\n",
      "The associated counts are\n",
      "[277459, 203659, 148873, 139578, 111796]\n",
      "and they should be\n",
      "[277459, 203659, 148873, 139578, 111796]\n"
     ]
    }
   ],
   "source": [
    "top_words, top_counts = epp.find_top_words(word_freq)\n",
    "print(f\"Your top 5 words are\\n{top_words[:5]}\\nand they should be\\n['the', 'to', 'and', 'of', 'a']\")\n",
    "print(f\"The associated counts are\\n{top_counts[:5]}\\nand they should be\\n[277459, 203659, 148873, 139578, 111796]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b) Make train and test splits of the dataset\n",
    "\n",
    "Here we divide the email features into a 80/20 train/test split (80% of data used to train the supervised learning model, 20% we withhold and use for testing / prediction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, y = epp.make_feature_vectors(top_words, num_emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "x_train, y_train, inds_train, x_test, y_test, inds_test = epp.make_train_test_sets(features, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes for train/test splits:\n",
      "Train (26100, 200), classes (26100,)\n",
      "Test (6525, 200), classes (6525,)\n",
      "\n",
      "They should be:\n",
      "Train (26100, 200), classes (26100,)\n",
      "Test (6525, 200), classes (6525,)\n"
     ]
    }
   ],
   "source": [
    "print('Shapes for train/test splits:')\n",
    "print(f'Train {x_train.shape}, classes {y_train.shape}')\n",
    "print(f'Test {x_test.shape}, classes {y_test.shape}')\n",
    "print('\\nThey should be:\\nTrain (26100, 200), classes (26100,)\\nTest (6525, 200), classes (6525,)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3c) Save data in binary format\n",
    "\n",
    "It adds a lot of overhead to have to run through your raw email -> train/test feature split every time you wanted to work on your project! In this step, you will export the data in memory to disk in a binary format. That way, you can quickly load all the data back into memory (directly in ndarray format) whenever you want to work with it again. No need to parse from text files!\n",
    "\n",
    "- Use numpy's `save` function to make six files in `.npy` format (e.g. `email_train_x.npy`, `email_train_y.npy`, `email_train_inds.npy`, `email_test_x.npy`, `email_test_y.npy`, `email_test_inds.npy`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store all trainiing and testing data sets into files\n",
    "# root directory of file\n",
    "root_filepath = \"data/subdata\"\n",
    "np.save(root_filepath + \"/email_train_x.npy\", x_train)\n",
    "np.save(root_filepath + \"/email_train_y.npy\", y_train)\n",
    "np.save(root_filepath + \"/email_train_inds.npy\", inds_train)\n",
    "np.save(root_filepath + \"/email_test_x.npy\", x_test)\n",
    "np.save(root_filepath + \"/email_test_y.npy\", y_test)\n",
    "np.save(root_filepath + \"/email_test_inds.npy\", inds_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Naive Bayes Classifier\n",
    "\n",
    "After finishing your email preprocessing pipeline, implement the one other supervised learning algorithm we we will use to classify email, **Naive Bayes**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a) Implement Naive Bayes\n",
    "\n",
    "In `naive_bayes.py`, implement the following methods:\n",
    "- Constructor\n",
    "- `train(data, y)`: Train the Naive Bayes classifier so that it records the \"statistics\" of the training set: class priors (i.e. how likely an email is in the training set to be spam or ham?) and the class likelihoods (the probability of a word appearing in each class — spam or ham).\n",
    "- `predict(data)`: Combine the class likelihoods and priors to compute the posterior distribution. The predicted class for a test sample is the class that yields the highest posterior probability.\n",
    "- `accuracy(y, y_pred)`: The usual definition :)\n",
    "\n",
    "\n",
    "#### Bayes rule ingredients: Priors and likelihood (`train`)\n",
    "\n",
    "To compute class predictions (probability that a test example belong to either spam or ham classes), we need to evaluate **Bayes Rule**. This means computing the priors and likelihoods based on the training data.\n",
    "\n",
    "**Prior:** $$P_c = \\frac{N_c}{N}$$ where $P_c$ is the prior for class $c$ (spam or ham), $N_c$ is the number of training samples that belong to class $c$ and $N$ is the total number of training samples.\n",
    "\n",
    "**Likelihood:** $$L_{c,w} = \\frac{N_{c,w} + 1}{N_{c} + M}$$ where\n",
    "- $L_{c,w}$ is the likelihood that word $w$ belongs to class $c$ (*i.e. what we are solving for*)\n",
    "- $N_{c,w}$ is the total count of **word $w$** in emails that are only in class $c$ (*either spam or ham*)\n",
    "- $N_{c}$ is the total number of **all words** that appear in emails of the class $c$ (*total number of words in all spam emails or total number of words in all ham emails*)\n",
    "- $M$ is the number of features (*number of top words*).\n",
    "\n",
    "#### Bayes rule ingredients: Posterior (`predict`)\n",
    "\n",
    "To make predictions, we now combine the prior and likelihood to get the posterior:\n",
    "\n",
    "**Log Posterior:** $$Log(\\text{Post}_{i, c}) = Log(P_c) + \\sum_{j \\in J_i}x_{i,j}Log(L_{c,j})$$\n",
    "\n",
    " where\n",
    "- $\\text{Post}_{i,c}$ is the posterior for class $c$ for test sample $i$(*i.e. evidence that email $i$ is spam or ham*). We solve for its logarithm.\n",
    "- $Log(P_c)$ is the logarithm of the prior for class $c$.\n",
    "- $x_{i,j}$ is the number of times the jth word appears in the ith email.\n",
    "- $Log(L_{c,j})$: is the log-likelihood of the jth word in class $c$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from naive_bayes_multinomial import NaiveBayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test `train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your class priors are: [0.24 0.26 0.25 0.25]\n",
      "and should be          [0.24 0.26 0.25 0.25].\n",
      "Your class likelihoods shape is (4, 6) and should be (4, 6).\n",
      "Your likelihoods are:\n",
      "[[0.15116 0.18497 0.17571 0.1463  0.16813 0.17374]\n",
      " [0.16695 0.17437 0.15742 0.16887 0.15677 0.17562]\n",
      " [0.14116 0.1562  0.19651 0.17046 0.17951 0.15617]\n",
      " [0.18677 0.18231 0.15884 0.12265 0.16755 0.18187]]\n",
      "and should be\n",
      "[[0.15116 0.18497 0.17571 0.1463  0.16813 0.17374]\n",
      " [0.16695 0.17437 0.15742 0.16887 0.15677 0.17562]\n",
      " [0.14116 0.1562  0.19651 0.17046 0.17951 0.15617]\n",
      " [0.18677 0.18231 0.15884 0.12265 0.16755 0.18187]]\n"
     ]
    }
   ],
   "source": [
    "num_test_classes = 4\n",
    "np.random.seed(0)\n",
    "data_test = np.random.random(size=(100, 6))\n",
    "y_test = np.random.randint(low=0, high=num_test_classes, size=(100,))\n",
    "\n",
    "nbc = NaiveBayes(num_classes=num_test_classes)\n",
    "nbc.train(data_test, y_test)\n",
    "\n",
    "print(f'Your class priors are: {nbc.class_priors}\\nand should be          [0.24 0.26 0.25 0.25].')\n",
    "print(f'Your class likelihoods shape is {nbc.class_likelihoods.shape} and should be (4, 6).')\n",
    "print(f'Your likelihoods are:\\n{nbc.class_likelihoods}')\n",
    "\n",
    "\n",
    "test_likelihoods = np.array([[0.15116, 0.18497, 0.17571, 0.1463 , 0.16813, 0.17374],\n",
    "       [0.16695, 0.17437, 0.15742, 0.16887, 0.15677, 0.17562],\n",
    "       [0.14116, 0.1562 , 0.19651, 0.17046, 0.17951, 0.15617],\n",
    "       [0.18677, 0.18231, 0.15884, 0.12265, 0.16755, 0.18187]])\n",
    "print(f'and should be\\n{test_likelihoods}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test `predict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your predicted classes are\n",
      "[3 0 3 1 0 1 1 3 0 3 0 2 0 2 1]\n",
      "and should be\n",
      "[3 0 3 1 0 1 1 3 0 3 0 2 0 2 1]\n"
     ]
    }
   ],
   "source": [
    "num_test_classes = 4\n",
    "np.random.seed(0)\n",
    "data_train = np.random.randint(low=0, high=num_test_classes, size=(100, 10))\n",
    "data_test = np.random.randint(low=0, high=num_test_classes, size=(15, 10))\n",
    "y_test = np.random.randint(low=0, high=num_test_classes, size=(100,))\n",
    "\n",
    "nbc = NaiveBayes(num_classes=num_test_classes)\n",
    "nbc.train(data_train, y_test)\n",
    "test_y_pred = nbc.predict(data_test)\n",
    "\n",
    "print(f'Your predicted classes are\\n{test_y_pred}\\nand should be\\n[3 0 3 1 0 1 1 3 0 3 0 2 0 2 1]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4b) Spam filtering\n",
    "\n",
    "Let's start classifying spam email using the Naive Bayes classifier.\n",
    "\n",
    "- Use `np.load` to load in the train/test split that you created last week.\n",
    "- Use your Naive Bayes classifier on the Enron email dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7:** Print out the accuracy that you get on the test set with Naive Bayes. It should be roughly 89%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import email_preprocessor as ep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in train and test split created\n",
    "x_train = np.load(\"data/subdata/email_train_x.npy\")\n",
    "y_train = np.load(\"data/subdata/email_train_y.npy\")\n",
    "inds_train = np.load(\"data/subdata/email_train_inds.npy\")\n",
    "x_test = np.load(\"data/subdata/email_test_x.npy\")\n",
    "y_test = np.load(\"data/subdata/email_test_y.npy\")\n",
    "inds_test = np.load(\"data/subdata/email_test_inds.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8993103448275862\n"
     ]
    }
   ],
   "source": [
    "# train and predict\n",
    "classifier = NaiveBayes(2)\n",
    "classifier.train(x_train, y_train)\n",
    "pred = classifier.predict(x_test)\n",
    "\n",
    "# check accuracy\n",
    "print(f\"Accuracy: {classifier.accuracy(y_test, pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4c) Confusion matrix\n",
    "\n",
    "To get a better sense of the errors that the Naive Bayes classifer makes, you will create a confusion matrix. \n",
    "\n",
    "- Implement `confusion_matrix` in `naive_bayes.py`.\n",
    "- Print out a confusion matrix of the spam classification results.\n",
    "\n",
    "**Debugging guidelines**:\n",
    "1. The sum of all numbers in your 2x2 confusion matrix should equal the number of test samples (6525).\n",
    "2. The sum of your spam row should equal the number of spam samples in the test set (3193)\n",
    "3. The sum of your ham row should equal the number of spam samples in the test set (3332)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8993103448275862\n",
      "[[3072.  172.]\n",
      " [ 485. 2796.]]\n",
      "\n",
      "# of Ham Emails: 3244\n",
      "# of Spam Emails: 3281\n",
      "\n",
      "Row sums: [3244. 3281.]\n",
      "Total sum: 6525.0\n",
      "Time taken: 5.527576923370361\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t0 = time.time()\n",
    "\n",
    "#### ADDED IN FOR FAIR COMPARSION LATTER IN NOTEBOOK\n",
    "# train and predict\n",
    "classifier = NaiveBayes(2)\n",
    "classifier.train(x_train, y_train)\n",
    "pred = classifier.predict(x_test)\n",
    "\n",
    "# check accuracy\n",
    "print(f\"Accuracy: {classifier.accuracy(y_test, pred)}\")\n",
    "#####################################################\n",
    "\n",
    "\n",
    "# print confusion matrix\n",
    "conf_matrix = classifier.confusion_matrix(y_test, pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "print(f\"\\n# of Ham Emails: {y_test[y_test == 0].size}\")\n",
    "print(f\"# of Spam Emails: {y_test[y_test == 1].size}\\n\")\n",
    "\n",
    "print(f\"Row sums: {np.sum(conf_matrix, axis=1)}\")\n",
    "print(f\"Total sum: {np.sum(conf_matrix)}\")\n",
    "\n",
    "t1 = time.time()\n",
    "print(f\"Time taken: {t1 -t0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 8:** Interpret the confusion matrix, using the convention that positive detection means spam (*e.g. a false positive means classifying a ham email as spam*). What types of errors are made more frequently by the classifier? What does this mean (*i.e. X (spam/ham) is more likely to be classified than Y (spam/ham) than the other way around*)?\n",
    "\n",
    "**Reminder:** Look back and make sure you are clear on which class indices correspond to spam/ham."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 8:** In the confusion matrix above, the first row represent the actual negative detections and the second row represents the acutal positive detections. The first column represents the emails predicted negative detection and the second column represents the predicted positive detection. The entry in the top left corner shows the number of negative detections that were predicted as negative detections (ham emails predicted as ham). The entry in the top right corner shows the number of negative detections that were incorrectly predicted as positive detections (ham emails predicted as spam emails). These are the number of false positives in my model. The entry in the bottom left corner are the positive detections predicted to be negative detections (number of spam emails predicted as ham emails). These are the number of false negatives in my model. Lastly, the entry in the bottom right corner are all positive detections predicted as positive detections (number of spam email predicted to be spam emails).\n",
    "\n",
    "It was more common to have false negatives than false positive because the number in the bottom right corner is greater than the number in the top right corner. This would imply that if someone used this algorithm to filter out ham and spam emails, there would be more spam emails making into this person's inbox than the number of real emails being marked as spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4d) Investigate the misclassification errors\n",
    "\n",
    "Numbers are nice, but they may not the best for developing your intuition. Sometimes, you want to see what an misclassification *actually looks like* to help you improve your algorithm. Here, you will take a false positive and a false negative misclassification and retrieve the actual text of the email so see which emails produced the error.\n",
    "\n",
    "- Determine the index of the **FIRST** false positive and false negative misclassification — i.e. 2 indices in total. Remember to use your `test_inds` array to look up the index of the emails BEFORE shuffling happened.\n",
    "- Implement the function `retrieve_emails` in `email_preprocessor.py` to return the string of the raw email at the error indices.\n",
    "- Call your function to print out the two emails that produced misclassifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 9:** Does it seem reasonable that each email message was misclassified? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 9:** I think the emails were reasonable misclassified. For the false positive, this appears to be reminder to some one that there was some meeting. This information is stored in the subject line, which isn't going to be too long in comparsion with the rest of the email. The rest email contains contact information. I believe that this contact information caused the error because I would expect spam email to be littered with spam email and that would make this email have more similarities to spam emails.\n",
    "\n",
    "The false negative makes sense since this is an email about some amazon order. At first glance, this is a long email refunding the client their money. I thought this email was not spam myself until I check the actual class of the email. The class is spam. Therefore, I assume that maybe emails from amazon.com were not suppose to sent to the user's email or this email could be potentially be bogus amazon.com email. Regardless, if I having issues seeing that this email is false, then it makes sense for the algorithm to make that mistake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False positive: y_test: 0.0; pred: 1\n",
      "False negative: y_test: 1.0; pred: 0\n",
      "\n",
      "False Positive:\n",
      " Subject: enron corp . board of directors meeting - october 9 , 2001\n",
      "kelly m . johnson\n",
      "executive assistant\n",
      "enron corp .\n",
      "tel : 713 - 853 - 6485\n",
      "fax : 713 - 853 - 2534\n",
      "e - mail : kelly . johnson @ enron . com\n",
      "\n",
      "False Negative:\n",
      " Subject: your amazon . com order ( # 104 - 9670681 - 0325567 )\n",
      "hello from amazon . com .\n",
      "we ' re writing to confirm that we have processed your refund for\n",
      "$ 18 . 00 for the above - referenced order .\n",
      "this amount should appear as a credit on your next credit card statement .\n",
      "for more information about this refund , please visit your account\n",
      "( http : / / www . amazon . com / your - account ) to view the above - referenced order .\n",
      "completed returns and refunds will appear at the bottom of the order\n",
      "summary page .\n",
      "we hope that this is a satisfactory resolution for you .\n",
      "if you have any questions , please contact us via e - mail , fax , or\n",
      "phone :\n",
      "e - mail : orders @ amazon . com\n",
      "fax : 1 - 206 - 266 - 2950\n",
      "phone : 1 - 800 - 201 - 7575 for us customers\n",
      "1 - 206 - 266 - 2992 for international customers\n",
      "thank you for shopping at amazon . com .\n",
      "amazon . com\n",
      "earth ' s biggest selection\n",
      "info @ amazon . com http : / / www . amazon . com /\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compare classes\n",
    "compare = y_test - pred\n",
    "\n",
    "# if false positive: then y_test[i] = 0 and pred = 1. Therefore, compare[i] = -1; \n",
    "# these are the minimum value of the list\n",
    "fp = np.where(compare == -1)[0]\n",
    "\n",
    "# if false negative: then y_test[i] = 1 and pred = 0. Therefore, compare[i] = 1; \n",
    "# these are the maximum value of the list\n",
    "fn = np.where(compare == 1)[0]\n",
    "\n",
    "# pull first index in list and place them into an ndarray to run retrieve emails function\n",
    "inds = np.array([fp[0], fn[0]])\n",
    "\n",
    "emails = ep.retrieve_emails(inds)\n",
    "\n",
    "# verify correctness of algorithm\n",
    "print(f\"False positive: y_test: {y_test[inds[0]]}; pred: {pred[inds[0]]}\")\n",
    "print(f\"False negative: y_test: {y_test[inds[1]]}; pred: {pred[inds[1]]}\")\n",
    "\n",
    "# print emails\n",
    "print(\"\\nFalse Positive:\\n\", emails[0])\n",
    "print(\"\\nFalse Negative:\\n\", emails[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Comparison with KNN\n",
    "\n",
    "\n",
    "- Run a similar analysis to what you did with Naive Bayes above. When computing accuracy on the test set, you may want to reduce the size of the test set (e.g. to the first 500 emails in the test set).\n",
    "- Copy-paste your `confusion_matrix` method into `knn.py` so that you can run the same analysis on a KNN classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from knn import KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.92\n",
      "[[3083.  161.]\n",
      " [ 371. 2910.]]\n",
      "Time taken: 372.0993673801422\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t0 = time.time()\n",
    "\n",
    "# train data\n",
    "classifier = KNN(2)\n",
    "classifier.train(x_train, y_train)\n",
    "\n",
    "# get predictions\n",
    "pred = classifier.predict(x_test, 5)\n",
    "\n",
    "# compute and print accuracy with first 500 samples\n",
    "print(f\"Accuracy: {classifier.accuracy(y_test[:500], pred[:500])}\")\n",
    "\n",
    "# compute confusion matrix on first 500 samples\n",
    "c_matrix = classifier.confusion_matrix(y_test, pred) \n",
    "print(c_matrix)\n",
    "\n",
    "t1 = time.time()\n",
    "print(f\"Time taken: {t1 -t0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 10:** What accuracy did you get on the test set (potentially reduced in size)?\n",
    "\n",
    "**Question 11:** How does the confusion matrix compare to that obtained by Naive Bayes (*If you reduced the test set size, keep that in mind*)?\n",
    "\n",
    "**Question 12:** Briefly describe at least one pro/con of KNN compared to Naive Bayes on this dataset.\n",
    "\n",
    "**Question 13:** When potentially reducing the size of the test set here, why is it important that we shuffled our train and test set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 10:** I got a 92% accuracy.\n",
    "\n",
    "**Answer 11:** Overall, the confusion matrix shows that this algorithm makes less false positives and false negatives. First, the sum of entries matrix is the same has the sum of all entries in the previous matrix. This confusion matrix made only 161 false positives where the confusion matrix for the Naive Baye algorithm made 172. This algorithm is better. Additionally, the confusion matrix for the KNN algorithm shows that this model only made 371 false negatives. This is better than than the 485 false negatives in the Naive Bayes algorithm.\n",
    "\n",
    "**Answer 12:** One pro to the KNN algorithm is that it is more accurate than the Naive Bayes algorithm (look at confusion matrix). However, one con of the KNN algorithm is that it takes much longer for the KNN algorithm to run than the Naive Bayes algorithm to the run. KNN took 6 minutes to run! Naive Bayes ran in 5 seconds. It is huge improvement. This shows that Naive Bayes could easily handle larger datasets where as KNN would struggle to run in a short peroid of time.\n",
    "\n",
    "**Answer 13:** This is to ensure that the samples used where randomized. If they weren't, it could be that the samples in an unrandomized subset of all emails could have a higher variance or some anomaly that would yield a prediction that is not representative of the rest of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Classify your own datasets\n",
    "\n",
    "- Find datasets that you find interesting and run classification on them using your KNN algorithm (and if applicable, Naive Bayes). Analysis the performance of your classifer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Better text preprocessing\n",
    "\n",
    "- If you look at the top words extracted from the email dataset, many of them are common \"stop words\" (e.g. a, the, to, etc.) that do not carry much meaning when it comes to differentiating between spam vs. non-spam email. Improve your preprocessing pipeline by building your top words without stop words. Analyze performance differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Feature size\n",
    "\n",
    "- Explore how the number of selected features for the email dataset influences accuracy and runtime performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Distance metrics\n",
    "- Compare KNN performance with the $L^2$ and $L^1$ distance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. K-Fold Cross-Validation\n",
    "\n",
    "- Research this technique and apply it to data and your KNN and/or Naive Bayes classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K-Fold Cross-Validation Extension**\n",
    "\n",
    "For this extension, I looked up the algorithm for the K-Fold Cross-Validation. The idea of the algorithm is that given a data set with its samples, I split the data set into k groups with roughly an equal number of samples per group. Then, iterating through each group, the i-th group would become a test data set and the remaining data sets would become the training data set. I would train the model (KNN or Naive Bayes in this case) and measure the performance of the model. Traditionally, MSE is used here. However, I have modified the algorithm to use the `accuracy` function to measure the quality of the model. I thought this information would be more meaningful than computing MSE. I know what accuracy means, but MSE does not provide any meaningful information about the ham/spam emails. Repeat this process for all groups and the result will be a `(M,)` array with accuracy of the model for all groups. Take the average of all accuracy values and that is what is returned by my K-Fold Cross-Validation method (KFCV).\n",
    "\n",
    "The purpose of this algorithm is to check the performance of a model. The interpretation of the results of this algorithm vary based on the metric used to mesure the performance of the model. In this case, accuracy measure performance. The higher the accuracy, the better.\n",
    "\n",
    "I created the algorithm for both KNN and Naive Bayes. Given that KNN takes forever to run on my computer, I tested KNN over a small number of emails. However, it appears that the algorithm does not work correctly on a subset of the data. The same occurs with the Naive Bayes algorithm. I have omitted testing code for the KNN KFCF algorithm for these reasons. However,using the full data set does not yield this error. I was interested in seeing relationship between average accuracy of the data set and the number of $k$. I expected that the average accuracy would increase with $k$ because when $k$ increases, the algorithm will create a larger training data set (more groups means that the size of each group decreases). Therefore, a larger training data set would be more accurate.\n",
    "\n",
    "However, the plot below shows that this is not case. It appears that it doesn't matter the value of $k$, the average accuracy remains constant for the values of $k$ I tested. I suppose that any variances of one groups gets \"washed out\" by the average accuracies of the other groups. This leads to more constant results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# change font size\n",
    "plt.rcParams['font.size'] = '12'\n",
    "\n",
    "# testing k-fold cross validation\n",
    "classifier = NaiveBayes(2)\n",
    "validation = []\n",
    "for i in range(3, 11):\n",
    "    validation.append(classifier.k_fold_cross_validation(features, y, i))\n",
    "    \n",
    "k_values = np.arange(3, 11)\n",
    "validation = np.array(validation)\n",
    "plt.plot(k_values, validation, \"k-\")\n",
    "plt.xticks(k_values)\n",
    "plt.xlabel(\"K Number of Groups\")\n",
    "plt.ylabel(\"Average Accuracy\")\n",
    "plt.yticks(np.arange(0.85, 0.9, 0.01))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing k-fold cross validation\n",
    "kclassifier = KNN(2)\n",
    "k_validation = []\n",
    "for i in range(3, 5):\n",
    "    k_validation.append(kclassifier.k_fold_cross_validation(features, y, 7, i))\n",
    "    \n",
    "kk_values = np.arange(3, 5)\n",
    "plt.plot(kk_values, k_validation, \"k-\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Email error analysis\n",
    "\n",
    "- Dive deeper into the properties of the emails that were misclassified (FP and/or FN) by Naive Bayes or KNN. What is their word composition? How many words were skipped because they were not in the training set? What could plausibly account for the misclassifications?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
